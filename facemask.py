# -*- coding: utf-8 -*-
"""FaceMask.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1StNkwTlPydZnalxcyR5FnwQ5u3GZ4KNa
"""

#import required libraries

import matplotlib.pyplot as plt
import numpy as np
import os
import random
from shutil import copyfile
import cv2
from keras.preprocessing.image import ImageDataGenerator
from matplotlib import pyplot
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

directory="/content/drive/MyDrive/data"
INIT_LR=1e-4
epochs=50
BS=128

def img_train_test_split(img_source_dir,train_size):
    if not os.path.exists('data'):
        os.makedirs('data')
    else:
        if not os.path.exists('data/train'):
            os.makedirs('data/train')
        if not os.path.exists('data/validation'):
            os.makedirs('data/validation')
    subdirs = [subdir for subdir in os.listdir(img_source_dir) if os.path.isdir(os.path.join(img_source_dir, subdir))]

    for subdir in subdirs:
        subdir_fullpath = os.path.join(img_source_dir, subdir)
        if len(os.listdir(subdir_fullpath)) == 0:
            print(subdir_fullpath + ' is empty')
            break

        train_subdir = os.path.join('data/train', subdir)
        validation_subdir = os.path.join('data/validation', subdir)

        # Create subdirectories in train and validation folders
        if not os.path.exists(train_subdir):
            os.makedirs(train_subdir)

        if not os.path.exists(validation_subdir):
            os.makedirs(validation_subdir)

        train_counter = 0
        validation_counter = 0

        # Randomly assign an image to train or validation folder

        for filename in os.listdir(subdir_fullpath):
            if filename.endswith(".jpg") or filename.endswith(".png"): 
                fileparts = filename.split('.')

                if random.uniform(0, 1) <= train_size:
                    copyfile(os.path.join(subdir_fullpath, filename), os.path.join(train_subdir, str(train_counter) + '.' + fileparts[1]))
                    train_counter += 1
                else:
                    copyfile(os.path.join(subdir_fullpath, filename), os.path.join(validation_subdir, str(validation_counter) + '.' + fileparts[1]))
                    validation_counter += 1
                    
        print('Copied ' + str(train_counter) + ' images to data/train/' + subdir)
        print('Copied ' + str(validation_counter) + ' images to data/validation/' + subdir)

img_train_test_split(directory,0.7)

train_path="/content/data/train"
test_path="/content/data/validation"

data_dir="/content/data/train"
categories=["with_mask","without_mask"]
for category in categories:
    path=os.path.join(data_dir,category)
    c=0
    for img in os.listdir(path):
        img=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)
        print(img.shape)
        plt.imshow(img)
        plt.show()
        c=c+1
        if c>2:
           break

train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,rescale=1./255,rotation_range=40,width_shift_range=0.2,height_shift_range=0.3,zoom_range=0.3,
                              horizontal_flip=True,fill_mode='nearest')

train_data=train_datagen.flow_from_directory(train_path,target_size=(224,224),batch_size=BS,class_mode='binary')

train_data.class_indices

validation_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,rescale=1./255)


validation_data=validation_datagen.flow_from_directory(test_path,target_size=(224,224),batch_size=BS,class_mode='binary')

#Building cnn model
cnn_model =Sequential( [Conv2D(filters=32, kernel_size=5, input_shape=[224, 224, 3]),
                                    MaxPooling2D(pool_size=(4,4)),
                                    Conv2D(filters=64, kernel_size=4),
                                    MaxPooling2D(pool_size=(3,3)),
                                    Conv2D(filters=128, kernel_size=3),
                                    MaxPooling2D(pool_size=(2,2)),                                    
                                    Conv2D(filters=256, kernel_size=2),
                                    MaxPooling2D(pool_size=(2,2)),
 
                                    Dropout(0.5),                                                                        
                                    Flatten(), # neural network beulding
                                    Dense(units=128, activation='relu'), # input layers
                                    Dropout(0.1),                                    
                                    Dense(units=256, activation='relu'),                                    
                                    Dropout(0.25),                                    
                                    Dense(units=2, activation='softmax') # output layer
])

from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping
callbacks=ModelCheckpoint(
    '/model.h5',
    monitor="val_accuracy",
    verbose=1,
    save_best_only=True,
    mode="max",
    save_freq="epoch"
)

# compile cnn model
cnn_model.compile(optimizer = Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
#cnn_model.compile(optimizer = Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
 
# train cnn model
history = cnn_model.fit(train_data, 
                          epochs=epochs, 
                          verbose=1, 
                          validation_data= validation_data,
                          callbacks=[callbacks])

cnn_model.save('/content/drive/MyDrive/model.h5')

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.plot(epochs, loss, 'g', label='Training Loss')
plt.plot(epochs, val_loss, 'y', label='Validation Loss')
plt.title('Training Loss and Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss/Accuracy')
plt.legend(loc='right')
plt.figure()

plt.show()
plt.savefig('plot.png')







